---
layout: page
title: LLM推理工程
permalink: /llm/engineering/inference/
description: 大语言模型推理优化与部署
---

# 大语言模型推理工程

本部分涵盖大语言模型的推理优化、部署策略和系统设计。

## 📋 概述

推理工程专注于使大语言模型在生产环境中高效、快速且具有成本效益。

## 🔬 研究领域

### 推理优化
- 模型量化（INT8、INT4、FP16）
- 剪枝与稀疏化
- 知识蒸馏
- 注意力优化

### 系统设计
- 成本效益解码
- 可扩展性与吞吐量
- 内存优化
- 硬件加速

### 部署策略
- 模型服务架构
- 负载均衡
- 缓存策略
- 多GPU推理

## 📚 论文与笔记

### 最新论文
- **[Step 3: Large yet Affordable Model System Co-design for Cost-effective Decoding](/llm/engineering/inference/2025-07-Step-3-is-Large-yet-Affordable-Model-system-Co-design-for-Cost-effective-Decoding.html)** - 成本效益模型解码的系统协同设计

*更多论文和笔记将在此处添加，随着处理和组织完成。*

## 🔗 相关分类

- **[训练工程](/llm/engineering/train/)** - 训练基础设施与优化
- **[模型架构](/llm/algorithm/models/)** - 大语言模型架构设计
- **[MLSys](/mlsys/)** - 机器学习系统与基础设施

---

*返回 [LLM工程](/llm/engineering/) | [研究论文](/blog/)* 